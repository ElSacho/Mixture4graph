{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import generator\n",
    "\n",
    "def calculate_distance_matrix(G):\n",
    "    A= nx.adjacency_matrix(G).toarray()\n",
    "    n_vertices=G.number_of_nodes()\n",
    "    distance_matrix = np.zeros((n_vertices, n_vertices))\n",
    "\n",
    "\n",
    "    for i in range(n_vertices):\n",
    "        for j in range(i + 1, n_vertices):\n",
    "            A_copy=A.copy()\n",
    "            euclidean_matrix = (A_copy - A_copy[i,j])**2\n",
    "            distance_matrix[i, j] = distance_matrix[j, i] = np.sqrt(euclidean_matrix.sum(axis=1)-A_copy[i,j]**2)[i]\n",
    "    \n",
    "    return distance_matrix\n",
    "\n",
    "def find_closest_clusters(distance_matrix):\n",
    "    np.fill_diagonal(distance_matrix, np.inf)\n",
    "    return np.unravel_index(np.argmin(distance_matrix, axis=None), distance_matrix.shape)\n",
    "\n",
    "def hierarchical_clustering(G, n_clusters):\n",
    "    n_vertices=G.number_of_nodes()\n",
    "    clusters = [[i] for i in range(n_vertices)]\n",
    "    distance_matrix = calculate_distance_matrix(G)\n",
    "\n",
    "    while len(clusters) > n_clusters:\n",
    "        i, j = find_closest_clusters(distance_matrix)\n",
    "\n",
    "        new_cluster = clusters[i] + clusters[j]\n",
    "        clusters.append(new_cluster)\n",
    "\n",
    "        clusters.pop(max(i, j))\n",
    "        clusters.pop(min(i, j))\n",
    "\n",
    "        new_distances = []\n",
    "        for k in range(len(distance_matrix)):\n",
    "            if k != i and k != j:\n",
    "                new_dist = min(distance_matrix[k, i], distance_matrix[k, j])\n",
    "                new_distances.append(new_dist)\n",
    "        new_distances.append(0.0)  \n",
    "\n",
    "        distance_matrix = np.delete(distance_matrix, [max(i, j), min(i, j)], axis=0)\n",
    "        distance_matrix = np.delete(distance_matrix, [max(i, j), min(i, j)], axis=1)\n",
    "        new_distances = np.array(new_distances)\n",
    "        distance_matrix = np.vstack((distance_matrix, new_distances[:-1]))\n",
    "        distance_matrix = np.column_stack((distance_matrix, new_distances))\n",
    "\n",
    "    return clusters\n",
    "\n",
    "# Example usage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n",
      "[[0], [1], [3], [9, 14, 19, 18, 17, 16, 15, 13, 12, 10, 7, 4, 6, 5, 8, 2, 11]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kk/m7r241y560174wvw5cvj2dfm0000gn/T/ipykernel_50443/1223222977.py:6: FutureWarning: adjacency_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  A= nx.adjacency_matrix(G).toarray()\n"
     ]
    }
   ],
   "source": [
    "pi = np.array([[0.1,1,0.1,0.1],[1,0.1,1,0.1],[0.1,1,0.1,1],[0.1,0.1,1,0.1]])\n",
    "priors = np.array([0.1, 0.4, 0.4, 0.1])\n",
    "G=generator.generate(20, pi, priors)\n",
    "\n",
    "print(G.number_of_edges())\n",
    "clusters=hierarchical_clustering(G,4)\n",
    "print(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         1.         1.41421356 1.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.41421356 0.         0.         1.41421356]\n",
      " [1.         0.         1.41421356 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "test_matrix=np.array([[0,1,0,1],[1,0,1,1], [1,1,0,0],[1,1,0,0]])\n",
    "distance_matrix=np.zeros((4,4))\n",
    "for i in range(4):\n",
    "        for j in range(i + 1, 4):\n",
    "            euclidean_matrix = (test_matrix - test_matrix[i,j])**2\n",
    "            distance_matrix[i, j] = distance_matrix[j, i] = np.sqrt(euclidean_matrix.sum(axis=1)-test_matrix[i,j]**2)[i]\n",
    "\n",
    "\n",
    "print(distance_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import em"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]]\n",
      "clusters [[2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [0, 1]]\n",
      "clusters [[3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [2, 0, 1]]\n",
      "clusters [[5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [2, 0, 1], [3, 4]]\n",
      "clusters [[7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [2, 0, 1], [3, 4], [5, 6]]\n",
      "clusters [[8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [3, 4], [5, 6], [7, 2, 0, 1]]\n",
      "clusters [[9], [11], [12], [13], [14], [15], [16], [17], [18], [19], [3, 4], [5, 6], [7, 2, 0, 1], [8, 10]]\n",
      "clusters [[11], [12], [13], [14], [15], [16], [17], [18], [19], [5, 6], [7, 2, 0, 1], [8, 10], [9, 3, 4]]\n",
      "clusters [[13], [14], [15], [16], [17], [18], [19], [5, 6], [7, 2, 0, 1], [8, 10], [9, 3, 4], [11, 12]]\n",
      "clusters [[14], [15], [16], [17], [18], [19], [7, 2, 0, 1], [8, 10], [9, 3, 4], [11, 12], [13, 5, 6]]\n",
      "clusters [[15], [16], [17], [18], [19], [8, 10], [9, 3, 4], [11, 12], [13, 5, 6], [14, 7, 2, 0, 1]]\n",
      "clusters [[16], [17], [18], [19], [9, 3, 4], [11, 12], [13, 5, 6], [14, 7, 2, 0, 1], [15, 8, 10]]\n",
      "clusters [[17], [18], [19], [11, 12], [13, 5, 6], [14, 7, 2, 0, 1], [15, 8, 10], [16, 9, 3, 4]]\n",
      "clusters [[18], [19], [11, 12], [14, 7, 2, 0, 1], [15, 8, 10], [16, 9, 3, 4], [17, 13, 5, 6]]\n",
      "clusters [[11, 12], [14, 7, 2, 0, 1], [15, 8, 10], [16, 9, 3, 4], [17, 13, 5, 6], [18, 19]]\n",
      "clusters [[15, 8, 10], [16, 9, 3, 4], [17, 13, 5, 6], [18, 19], [11, 12, 14, 7, 2, 0, 1]]\n",
      "clusters [[17, 13, 5, 6], [18, 19], [11, 12, 14, 7, 2, 0, 1], [15, 8, 10, 16, 9, 3, 4]]\n",
      "[[0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexandrefrancois/Documents/MVA/Probabilistic graphical models/Code projet/Mixture4graph/em.py:17: FutureWarning: adjacency_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  A = nx.adjacency_matrix(G)\n",
      "/Users/alexandrefrancois/opt/anaconda3/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/Users/alexandrefrancois/Documents/MVA/Probabilistic graphical models/Code projet/Mixture4graph/em.py:41: FutureWarning: adjacency_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  A= nx.adjacency_matrix(G).toarray()\n"
     ]
    }
   ],
   "source": [
    "pi = np.array([[0.1,1,0.1,0.1],[1,0.1,1,0.1],[0.1,1,0.1,1],[0.1,0.1,1,0.1]])\n",
    "priors = np.array([0.1, 0.4, 0.4, 0.1])\n",
    "G=generator.generate(20, pi, priors)\n",
    "\n",
    "tau_spectral=em.spectral_clustering(G, 4)\n",
    "print(tau_spectral)\n",
    "tau_hierarchical=em.hierarchical_clustering(G,4)\n",
    "print(tau_hierarchical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def modularity(G, clustering):\n",
    "    \"\"\"\n",
    "    G (graph)\n",
    "    clustering (list): n_vertices the index corresponds to the vertex, the value to the cluster\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    modularity=0\n",
    "    m=G.number_of_edges()\n",
    "    clustering_copy=clustering.copy()\n",
    "    for c in set(clustering_copy):\n",
    "        degree_sum=0\n",
    "        cluster = [index for index, value in enumerate(clustering) if value == c]\n",
    "\n",
    "        #cluster=[str(index) for index in cluster]\n",
    "\n",
    "\n",
    "        sub=G.subgraph(cluster)\n",
    "\n",
    "        degree_sum = sum([deg for _, deg in sub.degree]) \n",
    "        cluster_nedges=sub.number_of_edges()\n",
    "        modularity+=(cluster_nedges)/m - (degree_sum/(2*m))**2\n",
    "        \n",
    "        \n",
    "    \n",
    "    return modularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 2, 3, 2, 3, 3, 1, 1, 1, 3, 1, 3, 1, 1, 3, 2, 3, 2, 2]\n",
      "0.26234061355889404\n"
     ]
    }
   ],
   "source": [
    "G=generator.generate(20, pi, priors)\n",
    "clustering=list(np.random.randint(1,4,(1,20))[0])\n",
    "print(clustering)\n",
    "print(modularity(G, clustering))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_possible_community_pairs(communities):\n",
    "    seen_pairs = set()\n",
    "    for index, community in enumerate(communities):\n",
    "        for other_community in communities[index+1:]:\n",
    "                community_pair = tuple((community, other_community))\n",
    "                if community_pair not in seen_pairs:\n",
    "                    seen_pairs.add(community_pair)\n",
    "                    yield community_pair\n",
    "\n",
    "def modularity_based_clustering(graph):\n",
    "    # Initialize each node to be in its own community\n",
    "    communities = {node: node for node in graph.nodes}\n",
    "\n",
    "    # Function to calculate the modularity change if two communities are merged\n",
    "    def calculate_modularity_change(community1, community2):\n",
    "        # Implement the calculation of modularity change\n",
    "        pass\n",
    "\n",
    "    improved = True\n",
    "    while improved:\n",
    "        improved = False\n",
    "        delta_qs={}\n",
    "        for i, j in all_possible_community_pairs(communities):\n",
    "            delta_q = calculate_modularity_change(communities[i], communities[j])\n",
    "            delta_qs[(i,j)]=delta_q\n",
    "            max_delta_q, max_index=max(delta_qs.values()), max(delta_qs, key=lambda k: delta_qs[k])\n",
    "            if max_delta_q > 0:\n",
    "                # Merge communities\n",
    "                for node in communities:\n",
    "                    if communities[node] == max_index[0]:\n",
    "                        communities[node] = max_index[1]\n",
    "                improved = True\n",
    "\n",
    "    # Convert community mapping to a list format\n",
    "    community_list = [None] * len(graph.nodes)\n",
    "    for node, community in communities.items():\n",
    "        community_list[node] = community\n",
    "\n",
    "    return community_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key with the maximum value: c\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def modularity(G, clustering):\n",
    "    \"\"\"\n",
    "    G (graph)\n",
    "    clustering (list): n_vertices the index corresponds to the vertex, the value to the cluster\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    modularity=0\n",
    "    m=G.number_of_edges()\n",
    "    clustering_copy=clustering.copy()\n",
    "    for c in set(clustering_copy):\n",
    "        degree_sum=0\n",
    "        cluster = [index for index, value in enumerate(clustering) if value == c]\n",
    "\n",
    "        #cluster=[str(index) for index in cluster]\n",
    "\n",
    "\n",
    "        sub=G.subgraph(cluster)\n",
    "\n",
    "        degree_sum = sum([deg for _, deg in sub.degree]) \n",
    "        cluster_nedges=sub.number_of_edges()\n",
    "        modularity+=(cluster_nedges)/m - (degree_sum/(2*m))**2\n",
    "        \n",
    "        \n",
    "    \n",
    "    return modularity\n",
    "\n",
    "def best_modularity_change(G, clusters):\n",
    "    # Implement the calculation of modularity change\n",
    "    pass\n",
    "\n",
    "def modularity_clustering(G):\n",
    "    n_vertices=G.number_of_nodes()\n",
    "    clusters = [[i] for i in range(n_vertices)]\n",
    "    delta_q, i, j = best_modularity_change(G, clusters)\n",
    "    \n",
    "\n",
    "    while delta_q > 0:\n",
    "        new_cluster = clusters[i] + clusters[j]\n",
    "        clusters.append(new_cluster)\n",
    "\n",
    "        clusters.pop(max(i, j))\n",
    "        clusters.pop(min(i, j))\n",
    "\n",
    "        delta_q, i, j = best_modularity_change(clusters)\n",
    " \n",
    "\n",
    "    tau = np.zeros((n_vertices,len(clusters)))\n",
    "    for index, sublist in enumerate(clusters):\n",
    "        for l in sublist:\n",
    "            tau[l, index]=1\n",
    "    return tau"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
